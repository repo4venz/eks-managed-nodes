apiVersion: v1
kind: Pod
metadata:
  name: gpu-workload
spec:
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: node.kubernetes.io/instance-type  # Use cloud-specific
            operator: In
            values: [p3.2xlarge, p2.xlarge, g4dn.xlarge, g5.xlarge, g5.2xlarge]  # AWS types
  tolerations:
  - key: "nvidia.com/gpu"
    operator: "Exists"
    effect: "NoSchedule"
      # priorityClassName: "high-priority"  # Helps with preemption
  containers:
  - name: gpu-container
    image: nvidia/cuda:12.2.0-base-ubuntu22.04
    resources:
      limits:
        nvidia.com/gpu: 1
