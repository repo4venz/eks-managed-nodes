 # Configure node-exporter for worker nodes

serviceAccounts:
  server:
    name: ${service_account_name}
    annotations:
      eks.amazonaws.com/role-arn: ${prometheus_role_arn}
      eks.amazonaws.com/sts-regional-endpoints: "true"  # Use regional STS endpoints for better performance

prometheus-node-exporter:
  enabled: true
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:  # Hard requirement
        nodeSelectorTerms:
        - matchExpressions:
          - key: kubernetes.io/os  # Only Linux nodes
            operator: In
            values: [linux]
  hostRootFs:
    enabled: true  # Enable host root filesystem metrics (exposes disk usage, inode stats, etc.; ensure only trusted users can access these metrics to avoid leaking node-level information)
  tolerations:
    - operator: Exists  # Tolerate all taints
    - key: "eks.amazonaws.com/capacity-type"
      operator: "Equal"
      value: "spot"
      effect: "NoSchedule"

# Configure Prometheus and Grafana
# This section configures Prometheus and Grafana for monitoring and visualization
prometheus:
  prometheusSpec:
    storageSpec:
      volumeClaimTemplate:
        spec:
          storageClassName: ${storage_class_name} #ebs-sc
          accessModes:  ["ReadWriteMany"] # ["ReadWriteOnce"]    # for EBS use ReadWriteOnce and for EFS use ReadWriteMany
          resources:
            requests:
              storage: ${storage_size}
    podMetadata:
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "9090"
    serviceMonitorSelectorNilUsesHelmValues: false
    podMonitorSelectorNilUsesHelmValues: false
    serviceMonitorSelector: {}  # Selects all ServiceMonitors
    serviceMonitorNamespaceSelector: {}  # Looks in all namespaces
    podMonitorSelector: {}  # Selects all PodMonitors
    podMonitorNamespaceSelector: {}  # Looks in all namespaces
    scrapeInterval: 30s
    evaluationInterval: 30s
    ruleSelectorNilUsesHelmValues: false
    resources:
      requests:
        memory: 2Gi
        cpu: 1
    retention: ${prometheus_retention}  # 15d
    retentionSize: 5GiB
    additionalScrapeConfigs:
      - job_name: 'kubernetes-nodes'
        static_configs:
          - targets: ['localhost:9100']

      - job_name: 'kubelet'
        kubernetes_sd_configs:
          - role: node
        relabel_configs:
          - action: labelmap
            regex: __meta_kubernetes_node_label_(.+)

      - job_name: 'kubernetes-pods'
        kubernetes_sd_configs:
          - role: pod
        relabel_configs:
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
            action: keep
            regex: true
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
            action: replace
            target_label: __metrics_path__
            regex: (.+)
          - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
            action: replace
            regex: (.+):(?:\d+);(\d+)
            replacement: $1:$2
            target_label: __address__

      - job_name: 'kubernetes-services'
        kubernetes_sd_configs:
        - role: service
        relabel_configs:
        - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]
          action: keep
          regex: true
        - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_path]
          action: replace
          target_label: __metrics_path__
          regex: (.+)
        - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port]
          action: replace
          regex: ([^:]+)(?::\d+)?;(\d+)
          replacement: $1:$2
          target_label: __address__
        - action: labelmap
          regex: __meta_kubernetes_service_label_(.+)

  # Configure Prometheus to scrape metrics from Kubecost
  #    - job_name: 'kubecost'
  #      honor_labels: true
  #      scrape_interval: 1m
  #      scrape_timeout: 10s
  #      metrics_path: /metrics
  #     scheme: http
  #      static_configs:
  #    - targets: ['kubecost-cost-analyzer.kubecost.svc:9003']

  #    - job_name: 'node-exporter'
  #      static_configs:
  #    - targets: ['node-exporter.kube-system.svc:9100']

  #    - job_name: 'kube-state-metrics'
  #      static_configs:
  #    - targets: ['kube-state-metrics.kube-system.svc:8080']



  # Enable Grafana
grafana:
  enabled: true
  namespace: ${k8s_namespace}  # Default namespace for Grafana
  initChownData:
      enabled: false  # Disable the permission-changing init container  (only applicable for EFS)
  adminUser: 'admin'  # Default admin user
  adminPassword: 'admin123'  # Default admin password, change this in production
  persistence:      # Enable persistence for Grafana
    enabled: true
    storageClassName: ${storage_class_name} #ebs-sc
    accessModes:  ["ReadWriteMany"]  #["ReadWriteOnce"] # for EBS use ReadWriteOnce and for EFS use ReadWriteMany
    size: ${storage_size}  #5Gi
  ingress:
    enabled: true
    hosts:
      - ${grafana_ingress_hostname}  # Replace with your domain
    path: /
    pathType: Prefix
    tls:
      - secretName: grafana-tls  # Replace with your TLS secret name
        hosts:
          - ${grafana_ingress_hostname}  # Replace with your domain
    ingressClassName: 'nginx'  # Replace with your ingress class if needed
    annotations:
      kubernetes.io/ingress.class: nginx
      nginx.ingress.kubernetes.io/rewrite-target: /
      nginx.ingress.kubernetes.io/ssl-redirect: 'true'
      nginx.ingress.kubernetes.io/force-ssl-redirect: 'true'
      nginx.ingress.kubernetes.io/proxy-body-size: 100m  # Increase body size limit for large dashboards
      external-dns.alpha.kubernetes.io/hostname: ${grafana_ingress_hostname}  # For external DNS integration
      cert-manager.io/cluster-issuer: 'letsencrypt-${environment}'  # Use cert-manager for TLS
      nginx.ingress.kubernetes.io/proxy-connect-timeout: "60"
      nginx.ingress.kubernetes.io/proxy-read-timeout: "60"
      nginx.ingress.kubernetes.io/client-body-buffer-size: "8k"
  # Configure Loki as default logs datasource
  additionalDataSources:
    - name: Loki
      type: loki
      url: http://loki.${k8s_namespace}.svc.cluster.local:3100
      access: proxy
      isDefault: true  # Make Loki the default for logs
      jsonData:
        maxLines: 10000
        httpMethod: POST
        timeout: 30s
      version: 1
  # Sidecar to auto-discover dashboards
  sidecar:
    datasources:
      enabled: true
      label: grafana_datasource

# Enable Loki stack
loki:
  enabled: true
  namespace: ${k8s_namespace}  # Default namespace for Loki
  persistence:
    enabled: true
    storageClassName: ${storage_class_name}
    accessModes: ["ReadWriteMany"]
    size: ${loki_storage_size}

# Configure Promtail
promtail:
  enabled: true
  namespace: ${k8s_namespace}  # Default namespace for Promtail
  config:
    clients:
      - url: http://loki.${k8s_namespace}.svc.cluster.local:3100/loki/api/v1/push
    scrape_configs:
      - job_name: kubernetes-pods
        kubernetes_sd_configs:
          - role: pod
        relabel_configs:
          - source_labels: [__meta_kubernetes_namespace]
            target_label: namespace
          - source_labels: [__meta_kubernetes_pod_name]
            target_label: pod
          - source_labels: [__meta_kubernetes_pod_container_name]
            target_label: container
          - action: replace
            replacement: $1
            separator: /
            source_labels:
              - __meta_kubernetes_namespace
              - __meta_kubernetes_pod_name
            target_label: job
          - action: replace
            source_labels: [__meta_kubernetes_namespace]
            target_label: namespace
          - action: replace
            source_labels: [__meta_kubernetes_pod_name]
            target_label: pod
          - action: replace
            source_labels: [__meta_kubernetes_pod_container_name]
            target_label: container

# ServiceMonitors for scraping
serviceMonitor:
  loki:
    enabled: true
    namespace: ${k8s_namespace}
    endpoints:
      - port: http-metrics
        interval: 30s
    selector:
      matchLabels:
        app.kubernetes.io/name: loki
        app.kubernetes.io/instance: loki

  # Enable Alertmanager
alertmanager:
  enabled: true
  alertmanagerSpec:
    storage:
      volumeClaimTemplate:
        spec:
          storageClassName: ${storage_class_name} #ebs-sc
          accessModes:  ["ReadWriteMany"] #["ReadWriteOnce"]  # for EBS use ReadWriteOnce and for EFS use ReadWriteMany
          resources:
            requests:
              storage: 2Gi



